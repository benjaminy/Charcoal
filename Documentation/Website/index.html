<html>
<head>
<title>Charcoal: System-level Reactive and Interaction Programming for the Masses</title>
<style media="screen" type="text/css">
pre { display:inline }
.highlight {
  background-color:white;
  padding:0.3em;
  margin:0.3em;
}
</style>
</head>
<body style="background-color:darkgray">

<div style="background-color:seashell;width:35em;margin-left:auto;margin-right:auto;padding:2em">

<h1>(1/5) Charcoal</h1>
<p>Charcoal is a programming language project.  Charcoal's most
prominent features are:</p>
<ul>
  <li>Charcoal is a C dialect.
    <ul>
    <li>Mostly source-compatible with C
    <li>Calling C from Charcoal and vice-versa works with minimal fuss
    <li>Follows the "C philosophy"
    </ul>
  <li>Charcoal is designed to support concurrent/reactive/interactive
  programming better than the existing alternatives.
</ul>
<p>Charcoal is currently in a very early stage of development.  As of
this writing there is no Charcoal implementation, though work on one has
begun.</p>

<p>Here is the short version of what makes Charcoal different and
interesting:</p>

<ol>
  <li>Charcoal has a thread-like primitive called an <em>activity</em>.
  Why a new concurrency primitive?  Let's look at what programmers use
  today.
  <li><em>Event handlers</em>
  (<a href="http://en.wikipedia.org/wiki/Event_loop">1</a>,)
  are very popular for user interface programming and are relatively
  easy to understand, debug, etc., because each handler runs from start
  to finish without interference from other handlers.  The big problem
  with event handlers is that complex and/or long-running tasks have to
  be manually broken up into lots of little separate handlers.  This is
  a maintenance nightmare.  This problem is sometimes called "control
  flow inversion" or "stack ripping".
  <li><em>(Preemptive) Threads</em>
  (<a href="https://computing.llnl.gov/tutorials/pthreads/">1</a>,
   <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms684847(v=vs.85).aspx">2</a>,
   <a href="http://www.boost.org/doc/libs/1_53_0/doc/html/thread.html">3</a>,
   <a href="http://en.cppreference.com/w/cpp/thread">4</a>,
   <a href="http://www.javaworld.com/jw-04-1996/jw-04-threads.html">5</a>,
   <a href="http://cml.cs.uchicago.edu/pages/cml.html">6</a>)
  don't have the control flow inversion problem, but writing
  robust/reliable multithreaded code is <em>extremely</em> hard.  There
  is a whole cottage industry around trying to make it easier to
  implement reliable multithreaded programs.  The core of why
  multithreaded programming is hard is the combination of shared memory
  and preemption.  It's way too easy for one thread to interrupt another
  in the middle of a tricky sequence of operations and corrupt the state
  of the program.
  <li><em>Cooperative threads</em>
  (<a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms682661(v=vs.85).aspx">1</a>,
   <a href="http://dekorte.com/projects/opensource/libcoroutine/">2</a>,
   <a href="https://code.google.com/p/libtask/">3</a>,
   <a href="http://software.schmorp.de/pkg/libcoro.html">4</a>,
   <a href="http://lua-users.org/wiki/MultiTasking">5</a>,
   <a href="http://hackage.haskell.org/packages/archive/monad-coroutine/0.7.1/doc/html/Control-Monad-Coroutine.html">6</a>)
  are a kind of hybrid between event handlers and threads.  Like event
  handlers, only one cooperative thread can be running at a time.  The
  running cooperative thread must invoke a <em>yield</em> primitive to
  allow another to run.  This makes avoiding concurrency bugs easier.
  Like (conventional) threads, multiple cooperative threads can exist
  simultaneously, avoiding the control flow inversion problem of event
  handlers.  The problem with cooperative threads is that getting the
  yield invocations in just the right places is a tricky problem: too
  many leads to concurrency bugs and too few leads to one cooperative
  thread hogging the processor.
  <li>Charcoal introduces a new concurrency framework called
  <em>activities</em> that is a hybrid between cooperative and
  preemptive threads.  From an implementer's perspective the idea is to
  start with cooperative threads, but implicitly insert yield
  invocations relatively frequently.  The result is a kind of "chunky"
  preemption that we believe combines most of the software engineering
  benefits of the two multithreading models.  From a programmer's
  perspective activities behave mostly like preemptive threads, except
  getting the synchronization right is a lot easier.
</ol>

<p>Note: For the time being, the designers of Charcoal are not
interested in processor parallelism at all.  Concurrency and parallelism
are different, and Charcoal is about concurrency.</p>

<h1>(2/5) First Example</h1>

The first example is a multi-DNS lookup procedure.  This example is
shamelessly stolen from the
paper <a href="http://static.usenix.org/event/usenix07/tech/krohn.html">Events
Can Make Sense</a> by Krohn, Kohler, and Kaashoek.  The first version is
plain C.<br/>
<div class="highlight" style="font-family:monospace">
<table><tbody><tr>
<td align="right" valign="top">
1:<br/>2:<br/>3:<br/>4:<br/>5:<br/>6:<br/>7:<br/>8:<br/>9:<br/>10:<br/></td>
<td>&nbsp;</td>
<td valign="top">
<i>void</i> <b>multi_dns_seq</b>(<br/>
<pre>    </pre><i>size_t</i> <b>N</b>, <i>char **</i><b>names</b>,
 <b><u>struct</u></b> <i>addrinfo **</i><b>infos</b> )<br/>
{<br/>
<pre>    </pre><i>size_t</i> <b>i</b>;<br/>
<pre>    </pre><b><u>for</u></b>( i = 0; i &lt; N; ++i )<br/>
<pre>    </pre>{<br/>
<pre>        </pre>assert( 0 == getaddrinfo(<br/>
<pre>            </pre>names[i], NULL, NULL, &infos[i] ) );<br/>
<pre>    </pre>}<br/>
}
</tr></tbody></table>
</div>

<p>In <span style="font-family:monospace">multi_dns_seq</span>, we
sequentially perform <span style="font-family:monospace">N</span> DNS
lookups and return the results
in <span style="font-family:monospace">infos</span>.  Obviously the
error handling is pretty bare-bones here; I encourage to try to look
past that.  If we have a non-trivial number of names to look up, we
might be able to get through them faster by putting out several requests
simultaneously.  Here's how we can do that in Charcoal.</p>

<div class="highlight" style="font-family:monospace">
<table><tbody><tr>
<td align="right" valign="top">
1:<br/>2:<br/>3:<br/>4:<br/>5:<br/>6:<br/>7:<br/>8:<br/>9:<br/>10:<br/>
11:<br/>12:<br/>13:<br/>14:<br/>15:<br/>16:<br/>17:<br/>18:</td>
<td>&nbsp;</td>
<td valign="top">
<i>void</i> <b>multi_dns_conc</b>(<br/>
<pre>    </pre><i>size_t</i> <b>N</b>, <i>char</i> **<b>names</b>, <b><u>struct</u></b> <i>addrinfo</i> **<b>infos</b> )<br/>
{<br/>
<pre>    </pre><i>size_t</i> <b>i</b>, <b>done</b> = 0;<br/>
<pre>    </pre><i>semaphore_t</i> <b>done_sem</b>;<br/>
<pre>    </pre>sem_init( &amp;done_sem, 0 );<br/>
<pre>    </pre><b><u>for</u></b>( i = 0; i &lt; N; ++i )<br/>
<pre>    </pre>{<br/>
<pre>        </pre><b><u>activate</u></b> ( i )<br/>
<pre>        </pre>{<br/>
<pre>            </pre>assert( 0 == getaddrinfo(<br/>
<pre>                </pre>names[i], NULL, NULL, &amp;infos[i] ) );<br/>
<pre>            </pre><b><u>if</u></b>( ( ++done ) == N )<br/>
<pre>                </pre>sem_inc( &amp;done_sem );<br/>
<pre>        </pre>}<br/>
<pre>    </pre>}<br/>
<pre>    </pre>sem_dec( &amp;done_sem );<br/>
}
</td>
</tr></tbody></table>
</div>

<p>The most significant change here is
the <span style="font-family:monospace">activate</span> expression that
starts on line 9.  The expression or statement that follows
the <span style="font-family:monospace">activate</span> keyword (in this
example, the block from line 10 to 15) is run concurrently with the
activating code.  The activated statement runs in a
new <em>activity</em>.  Activities are cooperative in the sense that at
most one activity can be executing at a given time, and activities are
never preempted to run peer activities.</p>

<p>Activities are a kind of cooperative thread.</p>

<p>Activated statements can read and write variables declared in their
surrounding scope.  There are several instances in this example code: 
<span style="font-family:monospace">N</span>,
<span style="font-family:monospace">i</span>,
<span style="font-family:monospace">done</span>.  Some care must be
taken with these shared variables.  First, the programmer has to decide
whether the new activity should get a variable by-value or by-reference.
This is very much like the identically named options for parameter
passing in C++.  The default is by-reference.  For instance, all
activities in this example share the
same <span style="font-family:monospace">done</span> variable, and see
updates made by other activites.

can use any variable that a "normal" statement
could use, but the programmer has to make an important choice analogous
to by-value/by-reference parameter passing in C++.  By default variables
are treated as references.  In the example,
the <span style="font-family:monospace">done</span> variable is modified
by multiple activities.  This works fine.  In contrast, each activity
needs to know what the value
of <span style="font-family:monospace">i</span> was at activity creation
time.  That is why we put it in the by-value variable list.  The newly
created activity gets its own copy of each of the variables in this
list.</p>

<p>One weakness of our first concurrent multi-DNS lookup is that it
tries to look up all the names simultaneously.  If the list of names is
long, this might overwhelm the operating system or network.  We can
limit the number of outstanding look ups with a few modest changes to
the code:</p>

<div class="highlight" style="font-family:monospace">
<table><tbody><tr>
<td align="right" valign="top">
1:<br/>2:<br/>3:<br/>4:<br/>5:<br/>6:<br/>7:<br/>8:<br/>9:<br/>10:<br/>
11:<br/>12:<br/>13:<br/>14:<br/>15:<br/>16:<br/>17:<br/>18:<br/>19:<br/>20:<br/>
21:<br/>22:<br/>23:<br/>24:<br/>25:</td>
<td>&nbsp;</td>
<td valign="top">
<b><u>#define</u></b> <b>DEFAULT_MULTI_DNS_LIMIT</b> 10<br/>
<br/>
<i>void</i> <b>multi_dns_conc</b>(<br/>
<pre>    </pre><i>size_t</i> <b>N</b>, <i>size_t</i> <b>lim</b>,<br/>
<pre>    </pre><i>char</i> **<b>names</b>, <b><u>struct</u></b> <i>addrinfo</i> **<b>infos</b> )<br/>
{<br/>
<pre>    </pre><i>size_t</i> <b>i</b>, <b>done</b> = 0;<br/>
<pre>    </pre><i>semaphore_t</i> <b>done_sem</b>, <b>lim_sem</b>;<br/>
<pre>    </pre>sem_init( &amp;done_sem, 0 );<br/>
<pre>    </pre>sem_init( &amp;lim_sem,<br/>
<pre>        </pre>lim &lt; 1 ? DEFAULT_MULTI_DNS_LIMIT : lim );<br/>
<pre>    </pre><b><u>for</u></b>( i = 0; i &lt; n; ++i )<br/>
<pre>    </pre>{<br/>
<pre>        </pre>sem_dec( &amp;lim_sem );<br/>
<pre>        </pre><b><u>activate</u></b> ( i )<br/>
<pre>        </pre>{<br/>
<pre>            </pre>assert( 0 == getaddrinfo(<br/>
<pre>                </pre>names[i], NULL, NULL, &amp;infos[i] ) );<br/>
<pre>            </pre>sem_inc( &amp;lim_sem );<br/>
<pre>            </pre><b><u>if</u></b>( ( ++done ) == n )<br/>
<pre>                </pre>sem_inc( &amp;done_sem );<br/>
<pre>        </pre>}<br/>
<pre>    </pre>}<br/>
<pre>    </pre>sem_dec( &amp;done_sem );<br/>
}
</td>
</tr></tbody></table>
</div>

<p>Here we added a new semaphore
(<span style="font-family:monospace">lim_sem</span>) that the main
activity decrements before activating each look up.  The look up
activities increment the limit semaphore after completing the lookup,
allowing subsequent activations to occur.</p>

<p>An alternative pattern that would be more appropriate if we were
using processes or threads is for the main code to create a pool of
<span style="font-family:monospace">lim</span>
processes/threads/activities that would then carefully work their way
through the list of names.  This worker pool pattern is less clear for
applications like this, and is only preferable if creating new activities
is expensive.  In Charcoal, activating a statement is very cheap &mdash;
much closer to the cost of a procedure call than the cost of process
creation.</p>

<h1>(3/5) Concurrency</h1>

<p>Concurrency is a big topic.  In the most zoomed-out view, concurrent
software has multiple "active" components &mdash; sometimes
called <em>processes</em> or <em>tasks</em> &mdash; that can make
progress simultaneously.  The simultaneity can be physical (different
tasks literally executing simultaneously on separate processors) or
simulated by interleaving the execution of multiple tasks on a single
processor.  <a href="concurrency.html">Here</a> is my take on some of
the most important concepts that fit under the concurreny umbrella.</p>

<h1>(4/5) Reactive and Interactive Programming</h1>

<p>Often programmers and computer scientists think of programs as just
big functions/procedures: There is a pile of input; the program runs; it
produces a pile of output.  However, all programs are also to some
degree reactive and/or interactive.  Some programs (e.g. compilers)
emphasize the function/procedure aspect and some programs
(e.g. operating systems/GUI applications) emphasize the
reactive/interactive aspect.  The Charcoal project was motivated by the
observation that existing approaches to interactive programming leave
something to be desired.  For the record, those approaches are:</p>

<p>(Vocabulary: In these documents we will informally refer to
interactive programs as being composed of multiple <em>tasks</em> that
can be in progress simultaneously.  Tasks may react to external events,
or may run on their own for a long time.  Tasks may share access to
resources and/or pass messages to each other.)</p>

<h2>4.(1/2) Existing Approaches to Interactive Programming</h2>

<a href="./big_four.html">My thoughts</a>.


<h2>4.(2/2) New in Charcoal: Activities</h2>

<p>Charcoal introduces a new interactive programming primitive called
activities.  Like cooperative threads are a kind of compromise between
events and threads, activities are a kind of compromise between
preemptive and cooperative threads.  The goal is to avoid the awkward
problem of needing to put yields in just the right place, while not
reintroducing all the concurrency bug problems that come with true
preemptive threads.</p>


<h3>4.2.(1/3) Activities Compared to Threads</h3>

<h3>4.2.(2/3) Activities Compared to Cooperative Threads</h3>

<h3>4.2.(3/3) Activities Compared to Concurrency Primitive X</h3>

Lots of variations on the "Big Four" (processes, events, threads,
cooperative threads) have been proposed over the years.  If you would
like to see my take on how activities compare to any of these, let me
know.  I'll do my best to write something and update here.

<h1>(5/5) Charcoal Implementation</h1>

There are a few pieces to the Charcoal implementation:

<ul>
<li>Charcoal to C translation
<li>Charcoal runtime library
<li>System call interception
</ul>

<h2>5.(1/3) Charcoal to C Translation</h2>

<ul>
<li>activate extraction
<li>yield insertion
<li>unyielding translation
</ul>

<h3>5.1.(1/3) Activate</h3>

<p>The core piece of new syntax added in Charcoal is the activate
expression.  It looks like:</p>

<pre>activate (x,y,z) <statement or expression></pre>

<p>When this expression executes it starts a new activity to evaluate
its body, which can be an arbitrary statement or expression.  The
activate expression evaluates to a pointer to the new activity.</p>

<p>The list of variables has to do with how the new activity treats
variables local to whatever context the activation appears in.  By
default the new activity gets references to such variables, which means
that modifications made by one activity are visible to others.
Sometimes this is not desirable.  For the variables explicitly listed
in the activation expression, the activity gets its own copy whose
initial value is whatever the value of the variable was at the time the
activation expression is executed.</p>

<p>Here are the steps used to translate activate expressions to plain
C.</p>

<h4>Expression to Statement</h4>

<p>Activating an expression is defined to be the same as activating a
statement that returns that expression.  After performing this
transformation, all activate bodies are statements.</p>

<div class="highlight" style="font-family:monospace">
<b><u>activate</b></u> (<b>x</b>,...,<b>z</b>) <i>&lt;expression&gt;</i>
<br/><hr/>
<b><u>activate</b></u> (<b>x</b>,...,<b>z</b>) <b><u>return</b></u> <i>&lt;expression&gt;</i>
</div>

<h4>"Returning" from an Activity</h4>

<p>A return statement in an activity is different from a "normal" return
statement.  Returning from an activity has 2 effects: (1) the returned
value is saved in the activity's backing memory; (2) the activity stops
executing.  The returned value can then be accessed later by other
activities.  This is especially common when using the "future" pattern.
Exactly when an activity's backing memory gets deallocated is discussed
elsewhere.</p>

<p>(This translation only happens
within <span style="font-family:monospace">activate</span> bodies.)</p>

<div class="highlight" style="font-family:monospace">
<b><u>return</b></u> <i>&lt;expression&gt;</i>
<br/><hr/>
{&nbsp;self->rv = <i>&lt;expression&gt;</i>;<br/>
&nbsp;&nbsp;exit_activity; }
</div>

<h4>Variable Binding</h4>

<div class="highlight" style="font-family:monospace">
<b><u>activate</u></b> (<b>x</b>,...,<b>z</b>) <i>&lt;statement&gt;</i>
<br/><hr/>
args.a = &a; ... args.c = &c;<br/>
args.x = x; ... args.z = z;<br/>
<b><u>activate</b></u> {<br/>
&nbsp;&nbsp;x = args.x; ... z = args.z;<br/>
&nbsp;&nbsp;aptr = args.a; ... cptr = args.c;<br/>
&nbsp;&nbsp;<i>&lt;statement&gt;</i>[*aptr/a,...,*cptr/c]<br/>}
</div>

<h4>Activate Body Extraction</h4>

<p>In order to get to plain C, we extract the body of an activate
statement out into a function.</p>

<div class="highlight" style="font-family:monospace">
<b><u>activate</b></u> <i>&lt;statement&gt;</i>
<br/><hr/>
void __charcoal_activity_NNN( args )<br/>
{ <i>&lt;statement&gt;</i> }<br/>
...<br/>
&nbsp;&nbsp;__charcoal_activate( __charcoal_activity_NNN, args )</span>
</div>

<h3>5.1.(2/3) Yield Insertion</h3>

<p>The most novel part of Charcoal is that the language has implicit
yield invocations scattered about hither and yon.  This is what makes
the scheduling of Charcoal's activities a hybrid of preemptive and
cooperative.  They are cooperative in the sense that an activity must
yield in order for control to transfer to another activity (and it's
always possible to avoid/suppress yielding).  They are preemptive in the
sense that <em>by default</em> yield is implicitly invoked before
certain control flow transfers.  This gives activities a kind of "chunky"
preemptiveness that we hope will be easier for application programmers
to work with than conventional preemptive threads.</p>

<p>The intention is that most of the time you just don't have to worry
too much about either accidentally starving other activities (which can
be a problem with pure cooperative models) or invariants being violated
by another activity/thread interrupting at just the wrong time (which
can be a problem with pure preemptive models).</p>

<p>To be a little more precise, Charcoal has a yield on every
"backwards" control flow transition.  Important side note: this is
default behavior which can be overridden in variety of ways.  Every loop
(for, while) has a yield after every iteration.  gotos that go "up" in
the source have a yield.  Recursive procedure calls have a yield on both
call and return.</p>

<p>Indirect calls (e.g. through a function pointer) are a somewhat
tricky subject.  The easiest thing for the programmer is to assume that
all indirect calls have yields on call and return by default.</p>

<p>One huge difference between activities and conventional preemptive
threads is that data races
(<a href="http://blog.regehr.org/archives/490">ref 1</a>,
<a href="http://static.usenix.org/event/hotpar11/tech/final_files/Boehm.pdf">ref
2</a>) between activities simply do not exist.  Higher-level race
conditions are still possible, of course, but not having to worry about
low-level data races is a pretty big win.</p>

<h3>5.1.(3/3) Unyielding</h3>

<p>Charcoal comes with the usual set of synchronization primitives
(mutexes, condition variables, semaphores, barriers), also a nice set of
channel-based message passing primitives inspired by CML.  However,
quite often simpler and less error-prone synchronization patterns can
be used.</p>

<p>As we saw in the first example, simple shared memory accesses can
often go without any extra synchronization at all.  If you need a larger
section of code to execute atomically (relative to peer activities), you
can use the <span style="font-family:monospace">unyielding</span>
keyword.  <span style="font-family:monospace">unyielding</span> can be
applied to statements, expressions and procedure declarations.  In all
cases the effect is similar: the relevant statement/expression/procedure
will execute without yielding control to another activity, even if it
executes a yield statement.</p>

<div class="highlight" style="font-family:monospace">
<b><u>unyielding</u></b> <i>&lt;expression&gt;</i>
<br/><hr/>
(&nbsp;unyielding_enter,<br/>
&nbsp;&nbsp;__charcoal_v_NNN = <i>&lt;expression&gt;</i>,<br/>
&nbsp;&nbsp;unyielding_exit,<br/>
&nbsp;&nbsp;__charcoal_v_NNN&nbsp;)
</div>

<div class="highlight" style="font-family:monospace">
<b><u>unyielding</b></u> <i>&lt;statement&gt;</i>
<br/><hr/>
{&nbsp;unyielding_enter;<br/>
&nbsp;&nbsp;<i>&lt;statement&gt;</i>;<br/>
&nbsp;&nbsp;unyielding_exit&nbsp;}
</div>

<div class="highlight" style="font-family:monospace">
<b><u>unyielding</u></b> <i>&lt;fun decl&gt;</i> <i>&lt;fun body&gt;</i>
<br/><hr/>
<i>&lt;fun decl&gt;</i><br/>
{&nbsp;unyielding_enter;<br/>
&nbsp;&nbsp;<i>&lt;fun body&gt;</i>;<br/>
&nbsp;&nbsp;unyielding_exit&nbsp;}</span>
</div>

In all three cases, the "body" of
the <span style="font-family:monospace">unyielding</span> annotation
must be scanned for control transfers that might escape the body
(<span style="font-family:monospace">return</span>,
<span style="font-family:monospace">break</span>,
<span style="font-family:monospace">goto</span>, ...).
An <span style="font-family:monospace">unyielding_exit</span> is
inserted directly before such transfers.

<h4>When Should Unyielding Be Used?</h4>

<p>Unyielding can be used to make arbitrary chunks of code
"activity-safe", but some care needs to be taken in its use.  A good
example of its use is in a binary tree library.  Procedures that modify
a tree can/should be marked unyielding.</p>

<p>Probably most simple leaf procedures should be marked unyielding.<p>

<p>You need to be a little careful with
the <span style="font-family:monospace">unyielding</span> annotation.
It's easy to starve other activities by entering an unyielding
statement, then executing a long-running loop or making a blocking
syscall.  The situation to be especially vigilant about is using
unyielding on a block that usually executes reasonably quickly, but has
a path that is both infrequently executed and long-running/blocking.</p>

<p>Marking an expression/statement/procedure unyielding is very cheap.
In the worst case you add an increment and decrement of a thread-local
variable.  If the compiler can see nested unyielding statements, it can
optimize them out pretty easily, too.</p>

<h2>5.(2/3) Charcoal Runtime Library</h2>

<ul>
<li>yield
<li>scheduler
<li>stacks
</ul>

<h3>5.2.(1/3) yield</h3>

Well-behaved Charcoal programs invoke yield quite often (just for a
rough sense of scale, maybe a few times per microsecond on modern
processors).  This high frequency means that yield must be engineered
to:

<ul>
<li>Execute extremely quickly in the common case.
<li>Not cause a context switch most of the time.
</ul>

The first goal is important for based cycle counting reasons.  If yield
takes more than 10 or 20 instructions in the common case, avoiding
yields will become more of a performance tuning thing in Charcoal than I
want it to be.  Need to do some testing here.

The second goal is important because context switching has a non-trivial
direct cost (smaller than threads, but still not zero).  More
importantly, context switching can have high indirect costs if different
activities evict each others' working data from the caches.

<h3>5.2.(2/3) Scheduler</h3>

Under programmer control?

Interesting things about determinism?

<h3>5.2.(3/3) Stacks</h3>

One of the reasons threads are relatively expensive in most
implementations is that a large amount of memory has to be pre-allocated
for each thread's stack.  I really wanted to avoid that, so for now
we're using gcc's <a href="http://gcc.gnu.org/wiki/SplitStacks">split
stacks</a> and/or
LLVM's <a href="http://lists.cs.uiuc.edu/pipermail/llvmdev/2011-April/039260.html">segmented
stacks</a>.  One could go really extreme and heap allocate every
procedure call record individually.  I'm not aware of an easy way to do
that today, so that's future work.

<h2>5.(3/3) System Call Interception</h2>

Charcoal programs cannot be allowed to directly make syscalls that might
block for a long time, because multiple activities reside in a single
thread and a blocking syscall would block the whole thread.  The current
Charcoal implementation
uses <a href="http://software.intel.com/en-us/articles/pin-a-dynamic-binary-instrumentation-tool">Pin</a>
to intercept and translate syscalls.  (Other dynamic binary translation
tools like <a href="http://valgrind.org/">Valgrind</a> would probably
work just as well.)  The Charcoal runtime keeps a small pool of idle
threads meant for running syscalls.  When Pin intercepts a syscall, it
"moves" the call over to one of the idle threads and lets the scheduler
switch over to another activity on the calling thread.

</div>

</body>
</html>
