<html>
<head>
<title>Charcoal: System-level Reactive and Interaction Programming for the Masses</title>
<style media="screen" type="text/css">
pre { display:inline }
</style>
</head>
<body style="background-color:darkgray">

<div style="background-color:seashell;width:40em;margin-left:auto;margin-right:auto;padding:2em">

<h1>Charcoal</h1>
<p>Charcoal is a programming language project.  Charcoal's most
prominent features are:</p>
<ul>
<li>Charcoal is a C dialect.
  <ul>
  <li>Mostly source-compatible with C
  <li>Calling C from Charcoal and vice-versa works with minimal fuss
  <li>Follows the "C philosophy"
  </ul>
<li>Charcoal has a new concurrency primitive called <em>activities</em>
that are intended to support reactive and interactive programming better
than the existing alternatives.
</ul>
<p>Charcoal is currently in the very early research and development
stages.  As of this writing there is no Charcoal implementation, though
work has begun.</p>

<h1>First Example</h1>

The first example is a multi-DNS lookup procedure.  This example is
shamelessly stolen from the
paper <a href="http://static.usenix.org/event/usenix07/tech/krohn.html">Events
Can Make Sense</a> by Krohn, Kohler, and Kaashoek.
<br>
<pre>void multi_dns_seq( size_t N, char **names, struct addrinfo **infos )
{
    size_t i;
    for( i = 0; i < N; ++i )
    {
        assert( 0 == getaddrinfo( names[i], NULL, NULL, &infos[i] ) );
    }
}</pre>

<p>In <span style="font-family:monospace">multi_dns_seq</span>, we
sequentially perform <span style="font-family:monospace">N</span> DNS
lookups and return the results
in <span style="font-family:monospace">infos</span>.  Obviously the
error handling is pretty bare-bones here; I encourage to try to look
past that.  If we have a non-trivial number of names to look up, we
might be able to get through them faster by putting out several requests
simultaneously.  Here's how we can do that in Charcoal.</p>

<div style="font-family:monospace">
<table>
<tr>
<td align="right" valign="top">
1:<br>2:<br>3:<br>4:<br>5:<br>6:<br>7:<br>8:<br>9:<br>10:<br>
11:<br>12:<br>13:<br>14:<br>15:<br>16:<br>17:</td>
<td>&nbsp;</td>
<td valign="top">
<i>void</i> <b>multi_dns_conc</b>(<br>
<pre>    </pre><i>size_t</i> n, <i>char</i> **names, <b><u>struct</u></b> <i>addrinfo</i> **infos )<br>
{<br>
<pre>    </pre><i>size_t</i> <b>i</b>, <b>done</b> = 0;<br>
<pre>    </pre><i>semaphore_t</i> <b>done_sem</b>;<br>
<pre>    </pre>sem_init( &amp;done_sem, 0 );<br>
<pre>    </pre><b><u>for</u></b>( i = 0; i &lt; n; ++i )<br>
<pre>    </pre>{<br>
<pre>        </pre><b><u>activate</u></b> ( i )<br>
<pre>        </pre>{<br>
<pre>            </pre>assert( 0 == getaddrinfo(<br>
<pre>                </pre>names[i], NULL, NULL, &amp;infos[i] ) );<br>
<pre>            </pre>++done;<br>
<pre>            </pre><b><u>if</u></b>( done == n )<br>
<pre>                </pre>sem_inc( &amp;done_sem );<br>
<pre>        </pre>}<br>
<pre>    </pre>}<br>
<pre>    </pre>sem_dec( &amp;done_sem );<br>
}
</td>
</tr>
</table>
</div>

<p>The most significant change here is
the <span style="font-family:monospace">activate</span> statement on
line 7.  The <span style="font-family:monospace">activate</span>
statement <em>activates</em> another statement (in this example, the
block from line 8 to 13).  The activated statement runs in a
new <em>activity</em>, concurrently with the activating code.
Activities are cooperative in the sense that at most one activity can be
executing at a given time, and activities are never preempted to run
peer activities.</p>

<p>Activities are a kind of cooperative thread.</p>

<p>Activated statements can use any variable that a "normal" statement
could use, but the programmer has to make an important choice analogous
to by-value/by-reference parameter passing in C++.  By default variables
are treated as references.  In the example,
the <span style="font-family:monospace">done</span> variable is modified
by multiple activities.  This works fine.  In contrast, each activity
needs to know what the value
of <span style="font-family:monospace">i</span> was at activity creation
time.  That is why we put it in the by-value variable list.  The newly
created activity gets its own copy of each of the variables in this
list.</p>

<p>One weakness of our first concurrent multi-DNS lookup is that it
tries to look up all the names simultaneously.  If the list of names is
long, this might overwhelm the operating system or network.  We can
limit the number of outstanding look ups with a few modest changes to
the code:</p>

<div style="font-family:monospace">
<table>
<tr>
<td align="right" valign="top">
1:<br>2:<br>3:<br>4:<br>5:<br>6:<br>7:<br>8:<br>9:<br>10:<br>
11:<br>12:<br>13:<br>14:<br>15:<br>16:<br>17:</td>
<td>&nbsp;</td>
<td valign="top">
<b><u>#define</u></b> <b>DEFAULT_MULTI_DNS_LIMIT</b> 10<br>
<br>
<i>void</i> <b>multi_dns_conc</b>(<br>
<pre>    </pre><i>size_t</i> n, <i>size_t</i> lim, <i>char</i> **names, <b><u>struct</u></b> <i>addrinfo</i> **infos )<br>
{<br>
<pre>    </pre><i>size_t</i> <b>i</b>, <b>done</b> = 0;<br>
<pre>    </pre><i>semaphore_t</i> <b>done_sem</b>, <b>lim_sem</b>;<br>
<pre>    </pre>sem_init( &amp;done_sem, 0 );<br>
<pre>    </pre>sem_init( &amp;done_sem,<br>
<pre>        </pre>lim &lt; 1 ? DEFAULT_MULTI_DNS_LIMIT : lim );<br>
<pre>    </pre><b><u>for</u></b>( i = 0; i &lt; n; ++i )<br>
<pre>    </pre>{<br>
<pre>        </pre>sem_dec( &amp;lim_sem );<br>
<pre>        </pre><b><u>activate</u></b> ( i )<br>
<pre>        </pre>{<br>
<pre>            </pre>assert( 0 == getaddrinfo(<br>
<pre>                </pre>names[i], NULL, NULL, &amp;infos[i] ) );<br>
<pre>            </pre>sem_inc( &amp;lim_sem );<br>
<pre>            </pre>++done;<br>
<pre>            </pre><b><u>if</u></b>( done == n )<br>
<pre>                </pre>sem_inc( &amp;done_sem );<br>
<pre>        </pre>}<br>
<pre>    </pre>}<br>
<pre>    </pre>sem_dec( &amp;done_sem );<br>
}
</td>
</tr>
</table>
</div>

<p>Here we added a new semaphore
(<span style="font-family:monospace">lim_sem</span>) that the main
activity decrements before activating each look up.  The look up
activites increment the limit semaphore after completing the lookup,
allowing subsequent activations to occur.</p>

<p>An alternative pattern that would be more appropriate if we were
using processes or threads is for the main code to create a pool of
<span style="font-family:monospace">lim</span>
processes/threads/activities that would then carefully work their way
through the list of names.  This worker pool pattern is less clear for
applications like this, and is only prefereable if creating new activies
is expensive.  In Charcoal, activating a statement is very cheap &emdash
much closer to the cost of a procedure call than the cost of process
creation.</p>

<h1>Concurrency</h1>

<p>Concurrency is a big topic.  In the most zoomed-out view concurrenct
software has multiple "active" components &mdash; often
called <em>processes</em> or <em>tasks</em> &mdash; that can make
progress simultaneously.  The simultaneity can be physical (different
tasks literally being exceuted simultaneously on separate processors) or
simulated by interleaving the execution of multiple tasks on a single
processor.</p>

<p><a href="concurrency.html">Here</a> is my take on the next level of
detail behind the concept of concurrency in software.</p>

<h1>Reactive and Interactive Programming</h1>

<p>Often programmers and computer scientists think of programs as just
big functions/procedures: There is a pile of input; the program runs; it
produces a pile of output.  However, all programs are also to some
degree reactive and/or interactive.  Some programs (e.g. compilers)
emphasize the function/procedure aspect and some programs
(e.g. operating systems/GUI applications) emphasize the
reactive/interactive aspect.  The Charcoal project was motivated by the
observation that existing approaches to interactive programming leave
something to be desired.  For the record, those approaches are:</p>

<p>(Vocabulary: In these documents we will informally refer to
interactive programs as being composed of multiple <em>tasks</em> that
can be in progress simultaneously.  Tasks may react to external events,
or may run on their own for a long time.  Tasks may share access to
resources and/or pass messages to each other.)</p>

<h2>Existing Approaches to Interactive Programming</h2>

<a href="./big_four.html">My thoughts</a>.


<h2>New in Charcoal: Activities</h2>

<p>Charcoal introduces a new interactive programming primitive called
activities.  Like cooperative threads are a kind of compromise between
events and threads, activities are a kind of compromise between
preemptive and cooperative threads.  The goal is to avoid the awkward
problem of needing to put yields in just the right place, while not
reintroducing all the concurrency bug problems that come with true
preemptive threads.</p>


<h3>Activities Compared to Threads</h3>

<h3>Activities Compared to Cooperative Threads</h3>

<h3>Activities Compared to Concurrency Primitive X</h3>

Lots of variations on the "Big Four" (processes, events, threads,
cooperative threads) have been proposed over the years.  If you would
like to see my take on how activities compare to any of these, let me
know.  I'll do my best to write something and update here.

<h1>Charcoal Implementation</h1>

There are a few pieces to the Charcoal implementation:

<ul>
<li>Charcoal to C translation
<li>Charcoal runtime library
<li>System call interception
</ul>

<h2>Charcoal to C Translation</h2>

<ul>
<li>activate extraction
<li>yield insertion
<li>unyielding translation
</ul>

<h3>Activate</h3>

<p>The core piece of new syntax added in Charcoal is the activate
expression.  It looks like:</p>

<pre>activate (x,y,z) <statement or expression></pre>

<p>When this expression executes it starts a new activity to evaluate
its body, which can be an arbitrary statement or expression.  The
activate expression evaluates to a pointer to the new activity.</p>

<p>The list of variables has to do with how the new activity treats
variables local to whatever context the activation appears in.  By
default the new activity gets references to such variables, which means
that modifications made by one acitivity are visible to others.
Sometimes this is not desireable.  For the variables explicitly listed
in the activation expression, the activity gets its own copy whose
initial value is whatever the value of the variable was at the time the
activation expression is executed.</p>

<table border=1><tbody>
<tr><td valign="top">This</td><td valign="top">Translates to this</td></tr>
<tr>
<td width="50%" valign="top"><span style="font-family:monospace">activate (x,...,z) &lt;expression&gt;</span></td>
<td width="50%" valign="top"><span style="font-family:monospace">activate (x,...,z) return &lt;expression&gt;</span></td>
</tr>
<tr>
<td colspan="2"><em>Explanation</em>: Activating an expression is
defined to be the same as activating a statement that returns that
expression.</td>
</tr>
<tr>
<td valign="top">Within an activity ...<br>
    <span style="font-family:monospace">return &lt;expression&gt;</span></td>
<td valign="top"><span style="font-family:monospace">{ self->rv = &lt;expression&gt;;<br>
return; }</span></td>
</tr>
<tr>
<td colspan="2"><em>Explanation</em>: The activated code gets "lifted"
into its own implicitly defined function.  The return value from an
activity needs to get saved in the activity data structure so that other
activities can query it later.  The implicit function always returns
void.</td>
</tr>
<tr>
<td valign="top"><span style="font-family:monospace">activate (x,...,z) &lt;stmt&gt;</span></td>
<td valign="top"><span style="font-family:monospace">args.a = &a; ... args.c = &c;<br>
args.x = x; ... args.z = z;<br>
activate {<br>
&nbsp;&nbsp;x = args.x; ... z = args.z;<br>
&nbsp;&nbsp;aptr = args.a; ... cptr = args.c;<br>
&nbsp;&nbsp;&lt;stmt&gt;[*aptr/a,...,*cptr/c]<br>}</span></td>
</tr>
</tbody></table>

<h3>Yield Insertion</h3>

<p>The most novel part of Charcoal is that the language has implicit
yield invocations scattered about hither and yon.  This is what gives
Charcoal a nice hybrid between preemptive scheduling and cooperative
scheduling.  The intention is that most of the time you just don't have
to worry too much about either accidentally starving other activities
(which can be a problem with pure coorperative models) or data being
corrupted by other activities (which can be a problem with pure
preemptive models).</p>

<p>To be a little more precise, Charcoal has a yield on every
"backwards" control flow transition.  Important side note: this is
default behavior which can be overridden in variety of ways.  Every loop
(for, while) has a yield after every iteration.  gotos that go "up" in
the source have a yield.  Recursive procedure calls have a yield on both
call and return.</p>

<p>Indirect calls (e.g. through a function pointer) are a somewhat
tricky subject.  The easiest thing for the programmer is to assume that
all indirect calls have yields on call and return by default.</p>

<h3>Unyielding</h3>

<p>Charcoal comes with the usual set of syncronization primitives
(mutexes, condition variables, semaphores, barriers), also a nice set of
channel-based message passing primitives inspired by CML.  However,
quite often simpler and less error-prone synchronization patterns can
be used.</p>

<p>As we saw in the first example, simple shared memory accesses can
often go without any extra synchronization at all.  If you need a larger
section of code to execute atomically (relative to peer activities), you
can use the <span style="font-family:monospace">unyielding</span>
keyword.  <span style="font-family:monospace">unyielding</span> can be
applied to statements, expressions and procedure declarations.  In all
cases the effect is similar: the relevant statement/expression/procedure
will execute without yielding control to another activity, even if it
executes a yield statement.</p>

<p>You need to be a little careful with
the <span style="font-family:monospace">unyielding</span> modifier.
It's easy to starve other activities by entering an unyielding
statement, then executing a long-running loop or making a blocking
syscall.</p>

<h2>Charcoal Runtime Library</h2>

<ul>
<li>yield
<li>scheduler
<li>stacks
</ul>

<h3>yield</h3>

Well-behaved Charcoal programs invoke yield quite often (just for a
rough sense of scale, maybe a few times per microsecond on modern
processors).  This high frequency means that yield must be engineered
to:

<ul>
<li>Execute extremely quickly in the common case.
<li>Not cause a context switch most of the time.
</ul>

The first goal is important for based cycle counting reasons.  If yield
takes more than 10 or 20 instructions in the common case, avoiding
yeilds will become more of a performance tuning thing in Charcoal than I
want it to be.  Need to do some testing here.

The second goal is important because context switching has a non-trivial
direct cost (smaller than threads, but still not zero).  More
importantly, context switching can have high indirect costs if different
activities evict each others' working data from the caches.

<h3>Scheduler</h3>

Under programmer control?

Interesting things about determinism?

<h3>Stacks</h3>

One of the reasons threads are relatively expensive in most
implementations is that a large amount of memory has to be pre-allocated
for each thread's stack.  I really wanted to avoid that, so for now
we're using gcc's <a href="http://gcc.gnu.org/wiki/SplitStacks">split
stacks</a> and/or
LLVM's <a href="http://lists.cs.uiuc.edu/pipermail/llvmdev/2011-April/039260.html">segmented
stacks</a>.  One could go really extreme and heap allocate every
procedure call record individually.  I'm not aware of an easy way to do
that today, so that's future work.

<h2>System Call Interception</h2>

Charcoal programs cannot be allowed to directly make syscalls that might
block for a long time, because multiple activities reside in a single
thread and a blocking syscall would block the whole thread.  The current
Charcoal implementation
uses <a href="http://software.intel.com/en-us/articles/pin-a-dynamic-binary-instrumentation-tool">Pin</a>
to intercept and translate syscalls.  (Other dynamic binary translation
tools like <a href="http://valgrind.org/">Valgrind</a> would probably
work just as well.)  The Charcoal runtime keeps a small pool of idle
threads meant for running syscalls.  When Pin intercepts a syscall, it
"moves" the call over to one of the idle threads and lets the scheduler
switch over to another activity on the calling thread.

</div>

</body>
</html>
